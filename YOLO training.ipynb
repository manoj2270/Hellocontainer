{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP44TT+zKz/Ir+lXjvxwyJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manoj2270/Hellocontainer/blob/master/YOLO%20training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "junXRNczVVWl",
        "outputId": "197e5f46-33db-48f7-ad86-f83329a11e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrainYourOwnYOLO'...\n",
            "remote: Enumerating objects: 581, done.\u001b[K\n",
            "remote: Total 581 (delta 0), reused 0 (delta 0), pack-reused 581\u001b[K\n",
            "Receiving objects: 100% (581/581), 67.57 MiB | 23.19 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AntonMu/TrainYourOwnYOLO.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YarHwH0lVlOw",
        "outputId": "69c5e2bf-6451-4975-bc8e-e13c56f1973b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  TrainYourOwnYOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "path_to_zip_file = \"/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export.zip\"\n",
        "directory_to_extract_to = \"/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images\"\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "gMhdVtMxWjF4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/TrainYourOwnYOLO/1_Image_Annotation/Convert_to_YOLO_format.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xc_7GVXEzh",
        "outputId": "82cf2962-bd5d-4c53-f91b-8c94cfea0efb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/TrainYourOwnYOLO/1_Image_Annotation/Convert_to_YOLO_format.py\", line 79, in <module>\n",
            "    file.write(elem[0] + \"\\n\")\n",
            "numpy.core._exceptions.UFuncTypeError: ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U1')) -> None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/TrainYourOwnYOLO/2_Training/Download_and_Convert_YOLO_weights.py --is_tiny "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCPOKb4IX6d4",
        "outputId": "2efe7ecf-532e-4f1a-d464-dd471ab3e35c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading Raw yolov3-tiny.weights\n",
            "\n",
            "| |  #                                              | 1081 Elapsed Time: 0:00:00\n",
            "Downloaded Raw yolov3-tiny.weights in 3.2 seconds\n",
            "\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 16)\n",
            "2022-03-12 09:28:54.634201: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Parsing section maxpool_0\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 16, 32)\n",
            "Parsing section maxpool_1\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section maxpool_2\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section maxpool_3\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section maxpool_4\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section maxpool_5\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 1024, 256)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_9\n",
            "conv2d    linear (1, 1, 512, 255)\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section upsample_0\n",
            "Parsing section route_1\n",
            "Concatenating route layers: [<KerasTensor: shape=(None, None, None, 128) dtype=float32 (created by layer 'up_sampling2d')>, <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'leaky_re_lu_4')>]\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 384, 256)\n",
            "Parsing section convolutional_12\n",
            "conv2d    linear (1, 1, 256, 255)\n",
            "Parsing section yolo_1\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, None, None,   432         ['input_1[0][0]']                \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, None, None,   64         ['conv2d[0][0]']                 \n",
            " alization)                     16)                                                               \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['leaky_re_lu[0][0]']            \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, None, None,   4608        ['max_pooling2d[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, None, None,   128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['leaky_re_lu_1[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, None, None,   18432       ['max_pooling2d_1[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, None, None,   256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['leaky_re_lu_2[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, None, None,   73728       ['max_pooling2d_2[0][0]']        \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, None, None,   512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['leaky_re_lu_3[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, None, None,   294912      ['max_pooling2d_3[0][0]']        \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, None, None,   1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, None, None,   0          ['leaky_re_lu_4[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, None, None,   1179648     ['max_pooling2d_4[0][0]']        \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, None, None,   2048       ['conv2d_5[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, None, None,   0          ['leaky_re_lu_5[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, None, None,   4718592     ['max_pooling2d_5[0][0]']        \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, None, None,   4096       ['conv2d_6[0][0]']               \n",
            " rmalization)                   1024)                                                             \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, None, None,   262144      ['leaky_re_lu_6[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, None, None,   1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, None,   32768       ['leaky_re_lu_7[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, None, None,   512        ['conv2d_10[0][0]']              \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, None, None,   0           ['leaky_re_lu_9[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, None,   0           ['up_sampling2d[0][0]',          \n",
            "                                384)                              'leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, None,   1179648     ['leaky_re_lu_7[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, None,   884736      ['concatenate[0][0]']            \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, None, None,   2048       ['conv2d_8[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, None, None,   1024       ['conv2d_11[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, None,   130815      ['leaky_re_lu_8[0][0]']          \n",
            "                                255)                                                              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, None,   65535       ['leaky_re_lu_10[0][0]']         \n",
            "                                255)                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,858,734\n",
            "Trainable params: 8,852,366\n",
            "Non-trainable params: 6,368\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved Keras model to yolo-tiny.h5\n",
            "Read 8858734 of 8858734 from Darknet weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/TrainYourOwnYOLO/2_Training/Train_YOLO.py --is_tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKqBV-PWbMN0",
        "outputId": "32e45f28-fc4c-48e2-d296-2190ada0865f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create Tiny YOLOv3 model with 6 anchors and 10 classes.\n",
            "Load weights /content/TrainYourOwnYOLO/2_Training/src/keras_yolo3/yolo-tiny.h5.\n",
            "Freeze the first 42 layers of total 44 layers.\n",
            "8888888888888888888*********************************98888888888888888888888888888888888\n",
            "['/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aadicdwvxv.jpeg 1602,1247,1882,1473,0 2745,1125,3220,2070,1 512,2356,751,2811,1 1303,267,1344,325,2\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aadsfpjyjd.jpeg 187,1989,567,2432,1 937,2554,1412,2834,2 2162,723,3382,2224,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aafocvcywl.jpeg 2989,221,3319,673,0 2347,1844,2501,2056,3 390,3073,973,3553,0 314,2337,458,2527,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aabwhmwmfo.jpeg 2329,280,2768,809,1 1977,1256,3089,2332,2 738,2766,1059,3290,3 2564,2626,2836,2979,4 1602,682,1656,746,4\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aafqrzzqaz.jpeg 219,2251,1466,3349,2 1679,1817,1787,1930,0 1769,2368,2008,2716,0 2795,1826,3256,2264,0 3527,1121,3780,1397,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aageiauxqt.jpeg 3433,325,3708,633,0 3410,1763,3867,2296,0 2705,1356,2918,1831,4 965,1564,2149,2870,4 3017,3629,3116,3742,4\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aahbtwuclx.jpeg 1873,1166,2416,2454,1 3085,999,3225,1162,0 3247,2192,3338,2328,1 3347,2531,3428,2635,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aahllcltyh.jpeg 1421,366,1602,542,5 2348,619,2655,1116,6 2881,832,2985,927,7 2122,1672,2994,2870,7\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aahhpidfvk.jpeg 997,393,2353,1713,0 3320,1464,3921,1953,0 1195,3869,1345,3995,5\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aakdibajng.jpeg 38,682,174,836,3 2434,886,2547,1012,8 2063,1067,2145,1184,6 1982,1948,3044,3241,5 2095,3602,2389,3932,9\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaldugztnk.jpeg 3116,447,3469,841,0 2506,2567,3080,3150,0 1082,1369,1955,2780,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aalwjaqqgi.jpeg 1403,41,1512,199,0 3076,2061,3171,2206,3\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aakrmobtqc.jpeg 3098,258,3216,434,7 2972,2201,3605,3205,3 870,2477,2099,3747,2\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aalsrckbqu.jpeg 1720,895,2068,1342,0 2755,2671,3040,3299,1 1788,3675,2009,3896,2 1290,3449,1485,3684,7 2167,2197,2235,2255,9\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aallxsmovh.jpeg 1494,59,1679,334,3 2158,538,2407,945,6 1706,1134,1932,1455,9 2583,3101,2972,3571,9 1516,3060,1828,3562,9\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aangsionza.jpeg 2579,646,2886,1049,6 2194,1550,3369,2997,0 1064,2721,1322,3037,6 974,3223,1277,3485,9\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaprdfvial.jpeg 1168,660,1625,2070,1 2782,1433,3021,1776,8 536,2734,698,2866,8 802,3119,947,3295,0 1431,2653,2366,3507,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaoyiebsqm.jpeg 1200,298,1557,719,0 3311,393,3446,551,0 2118,2906,2190,2969,0 192,2762,816,3394,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaofnmvaxy.jpeg 879,348,1928,1537,5 2664,1139,2967,1532,5 1647,1907,2755,3277,5 3415,3137,3492,3241,4\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaplmjacsq.jpeg 1313,113,1584,425,0 2023,741,2461,1139,0 843,1980,1932,3327,0 3044,3205,3229,3412,2\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaqfvwndck.jpeg 942,1076,2118,2549,0 2913,3218,3320,3720,5 1553,3453,1733,3647,0 1417,32,1498,90,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aasxxjhjqg.jpeg 1742,172,1792,235,2 1557,628,2786,1849,0 992,1907,1087,1980,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aasnvryfhh.jpeg 355,3453,531,3647,2 1914,1763,2927,3191,2 2194,1044,2294,1220,3 2240,714,2285,782,4\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aarjgtevyn.jpeg 1580,1229,2484,2174,0 1299,2540,2167,3385,0 2999,1677,3157,1898,5\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaraqfdqjc.jpeg 594,2924,861,3164,0 924,2328,1218,2640,0 3017,2924,3157,3123,0 1986,692,3342,2093,0 490,1049,536,1085,6\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aawpiognux.jpeg 992,416,1191,764,0 902,1781,1991,3318,5 2805,2811,3089,3159,5 2231,3747,2497,3982,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaupfgnhno.jpeg 2330,461,3012,1342,9 1055,945,1693,1989,3 2918,1934,3026,2075,7 2814,2359,3153,2753,0 1164,2753,1299,2902,8\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aaxhciioqn.jpeg 490,1397,716,1577,0 1751,1107,2981,2617,1 3442,2979,3713,3385,1 3121,3837,3220,3977,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aawbkkbcks.jpeg 1792,3051,1941,3195,0 2334,3042,2592,3327,4 2289,1211,3252,2400,5 2782,520,2913,673,7\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aayphxjdiw.jpeg 576,2405,1733,3607,9 2872,3327,3144,3643,8 2615,705,3541,1971,2 499,542,1788,1817,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aazzoqsmap.jpeg 1941,673,2149,1338,1 1159,1650,1955,2667,1 2447,2423,2723,2744,0 459,2260,640,2472,4\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abbymdmgzq.jpeg 2258,755,3451,1749,5 1431,1211,1846,1636,0 2651,2165,2922,2585,1 816,2242,1553,3195,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aazwmzycuw.jpeg 364,1704,445,1799,0 1919,646,3415,2179,0 3740,2305,3781,2350,2 3686,3205,3835,3345,7 3071,3810,3116,3855,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abdeaqwptd.jpeg 644,344,1702,1297,0 2194,832,3347,1993,0 504,2328,1055,2757,0 3817,3738,3885,3810,0 2660,2884,3284,3259,2\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/aayxelugmy.jpeg 3532,791,3718,1134,0 965,836,2506,2395,0 2850,3304,3003,3869,1 1625,3779,1819,3959,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abfttmdflx.jpeg 61,818,179,931,9 527,294,1064,805,7 1964,420,2221,759,3 3338,1067,3501,1266,3 1991,1934,3338,3421,5\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abfdzpciid.jpeg 1019,569,1123,687,8 3505,791,3582,895,1 1485,1026,3058,2563,5 852,3015,1119,3372,7\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abgykaokjh.jpeg 1571,158,1769,416,0 269,1003,350,1089,0 2158,3498,2221,3575,0 2484,2129,3424,3295,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abfhuqyceb.jpeg 834,1116,1006,1302,8 979,2233,1742,3214,7 3040,3498,3157,3607,8\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abgmdxywua.jpeg 3144,497,3446,931,8 2461,2301,3139,3421,5 766,2540,1195,3729,1 1512,592,2438,1663,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abikwfvjhf.jpeg 2208,36,2556,425,3 1982,1297,2673,2468,1 2592,2947,3216,3553,5\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abhhhofbiz.jpeg 414,682,590,999,1 432,1876,1833,3399,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abibbfrxhd.jpeg 1164,420,1647,868,0 2384,244,2542,398,9 3564,1049,3686,1193,8 1562,1347,1941,2856,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abivyfkqqc.jpeg 635,755,2027,2264,5 1462,2441,1553,2621,1 2958,2649,3121,2861,2\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abilnagvsr.jpeg 3049,1356,3189,1546,2 3464,2549,3858,3019,2 680,1663,1932,3159,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abjirflhvv.jpeg 169,1523,459,1894,5 1123,1433,1675,2066,8 2362,2273,3306,3516,8 504,2698,1593,3941,7\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abjhddkxns.jpeg 603,601,703,728,3 2145,927,2918,1681,5 305,1645,626,2047,5 1069,1939,1327,2337,6 1571,3684,1824,3955,8\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abkpuahxwi.jpeg 278,185,531,533,1 3211,1031,3867,1650,2 576,2811,685,2938,2 807,3471,1015,3724,2 1684,2418,2588,3783,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abjwepbtfz.jpeg 3501,845,3663,967,0 1548,538,2795,2084,5 2041,2499,2497,3177,5 531,2920,1105,3489,8\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abjuvupvco.jpeg 599,438,1394,1713,1 3731,705,3831,827,8 2832,2079,2945,2246,1 1110,2066,1403,2350,0 3003,3073,3211,3318,6\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/ablxaraptb.jpeg 1666,1605,2294,2861,1 3162,1953,3473,2481,4 3663,2007,3803,2138,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abmbufyqlt.jpeg 386,375,658,664,0 1593,1243,1833,2450,1 3478,1962,3767,2237,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abkqwvzpel.jpeg 3238,556,3663,1284,3 929,384,2240,1803,5 1941,2567,2240,2915,9 3482,3092,3745,3458,9 2628,3525,2872,3815,9\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abkymbbiib.jpeg 346,1790,567,2206,1 215,2974,572,3358,4 1521,3218,1593,3327,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/ablwsriwvs.jpeg 725,759,1241,2142,1 2881,755,3501,1437,7 3871,687,3962,827,7 1544,2716,1751,3015,3 2872,3453,2981,3593,3\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abndcmefoo.jpeg 1331,262,1562,520,2 2443,1270,2696,2188,1 206,3177,531,3571,5 983,3652,1101,3819,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abnlhghfrc.jpeg 2990,307,3180,479,3 2841,759,3098,1040,7 1693,1049,1950,1311,4 2217,1595,3451,3051,2 495,2314,1024,3105,5\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abnpgslqow.jpeg 1598,456,2759,1862,2 621,3101,802,3349,8 445,3806,554,3923,3\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abodngfjkb.jpeg 1548,1577,1932,3069,1 2936,2721,3148,3051,6 2714,3666,2845,3824,1 3934,1849,4000,1930,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/abnwvixvum.jpeg 884,1641,1313,2337,5 2447,1564,2972,2721,1 3392,3431,3564,3611,8']\n",
            "Train on 54 samples, val on 6 samples, with batch size 32.\n",
            "Epoch 1/51\n",
            "1/1 [==============================] - 31s 31s/step - loss: 3338.9412 - val_loss: 3095.1912\n",
            "Epoch 2/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 3139.8811 - val_loss: 2877.6301\n",
            "Epoch 3/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 2913.2153 - val_loss: 2672.1753\n",
            "Epoch 4/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 2627.5698 - val_loss: 2436.7100\n",
            "Epoch 5/51\n",
            "1/1 [==============================] - 27s 27s/step - loss: 2447.0522 - val_loss: 2214.2224\n",
            "Epoch 6/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 2302.3416 - val_loss: 2082.8228\n",
            "Epoch 7/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2064.4324 - val_loss: 1926.5295\n",
            "Epoch 8/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1895.9507 - val_loss: 1727.3755\n",
            "Epoch 9/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1802.5891 - val_loss: 1586.1489\n",
            "Epoch 10/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1631.9634 - val_loss: 1464.7213\n",
            "Epoch 11/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1478.8772 - val_loss: 1362.4381\n",
            "Epoch 12/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1446.7194 - val_loss: 1223.3816\n",
            "Epoch 13/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1262.9993 - val_loss: 1161.0466\n",
            "Epoch 14/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1176.6022 - val_loss: 1047.2645\n",
            "Epoch 15/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 1040.2133 - val_loss: 935.9974\n",
            "Epoch 16/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 954.3588 - val_loss: 869.8107\n",
            "Epoch 17/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 922.0624 - val_loss: 813.2785\n",
            "Epoch 18/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 817.4183 - val_loss: 770.0125\n",
            "Epoch 19/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 772.7787 - val_loss: 677.8271\n",
            "Epoch 20/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 667.1838 - val_loss: 632.9214\n",
            "Epoch 21/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 613.2521 - val_loss: 563.3562\n",
            "Epoch 22/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 585.4692 - val_loss: 497.9012\n",
            "Epoch 23/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 540.4428 - val_loss: 495.2670\n",
            "Epoch 24/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 489.1478 - val_loss: 445.1936\n",
            "Epoch 25/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 467.7426 - val_loss: 423.6016\n",
            "Epoch 26/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 427.0529 - val_loss: 398.9873\n",
            "Epoch 27/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 389.3784 - val_loss: 360.9834\n",
            "Epoch 28/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 375.5544 - val_loss: 327.6829\n",
            "Epoch 29/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 342.4633 - val_loss: 305.5562\n",
            "Epoch 30/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 312.3125 - val_loss: 302.2159\n",
            "Epoch 31/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 297.1220 - val_loss: 276.4991\n",
            "Epoch 32/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 295.0197 - val_loss: 261.2936\n",
            "Epoch 33/51\n",
            "1/1 [==============================] - 27s 27s/step - loss: 257.8824 - val_loss: 250.2230\n",
            "Epoch 34/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 243.2235 - val_loss: 230.6528\n",
            "Epoch 35/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 229.3890 - val_loss: 224.0845\n",
            "Epoch 36/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 240.3201 - val_loss: 211.0909\n",
            "Epoch 37/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 212.4759 - val_loss: 202.2402\n",
            "Epoch 38/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 213.1714 - val_loss: 191.8118\n",
            "Epoch 39/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 188.1485 - val_loss: 184.4890\n",
            "Epoch 40/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 184.4466 - val_loss: 173.4588\n",
            "Epoch 41/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 175.4483 - val_loss: 170.9287\n",
            "Epoch 42/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 162.6576 - val_loss: 167.2809\n",
            "Epoch 43/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 156.1142 - val_loss: 154.3640\n",
            "Epoch 44/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 163.2161 - val_loss: 152.2900\n",
            "Epoch 45/51\n",
            "1/1 [==============================] - 28s 28s/step - loss: 149.4583 - val_loss: 146.3206\n",
            "Epoch 46/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 155.1867 - val_loss: 147.8746\n",
            "Epoch 47/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 137.5022 - val_loss: 148.6331\n",
            "Epoch 48/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 131.4628 - val_loss: 141.0581\n",
            "Epoch 49/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 128.8597 - val_loss: 136.2314\n",
            "Epoch 50/51\n",
            "1/1 [==============================] - 26s 26s/step - loss: 132.1395 - val_loss: 129.7708\n",
            "Epoch 51/51\n",
            "1/1 [==============================] - 23s 23s/step - loss: 131.5759 - val_loss: 134.9811\n",
            "Unfreeze all layers.\n",
            "Train on 54 samples, val on 6 samples, with batch size 4.\n",
            "Epoch 52/102\n",
            "13/13 [==============================] - 45s 3s/step - loss: 106.5132 - val_loss: 131.5776 - lr: 1.0000e-04\n",
            "Epoch 53/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 75.6142 - val_loss: 107.9194 - lr: 1.0000e-04\n",
            "Epoch 54/102\n",
            "13/13 [==============================] - 41s 3s/step - loss: 64.6623 - val_loss: 104.8491 - lr: 1.0000e-04\n",
            "Epoch 55/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 56.8961 - val_loss: 79.1110 - lr: 1.0000e-04\n",
            "Epoch 56/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 52.3011 - val_loss: 75.8589 - lr: 1.0000e-04\n",
            "Epoch 57/102\n",
            "13/13 [==============================] - 41s 3s/step - loss: 48.6593 - val_loss: 53.6416 - lr: 1.0000e-04\n",
            "Epoch 58/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 43.2238 - val_loss: 57.2451 - lr: 1.0000e-04\n",
            "Epoch 59/102\n",
            "13/13 [==============================] - 41s 3s/step - loss: 44.4053 - val_loss: 62.6890 - lr: 1.0000e-04\n",
            "Epoch 60/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 41.8869 - val_loss: 51.5829 - lr: 1.0000e-04\n",
            "Epoch 61/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 41.8508 - val_loss: 41.2284 - lr: 1.0000e-04\n",
            "Epoch 62/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 36.0122 - val_loss: 44.7338 - lr: 1.0000e-04\n",
            "Epoch 63/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 36.0028 - val_loss: 35.1903 - lr: 1.0000e-04\n",
            "Epoch 64/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 37.9589 - val_loss: 50.8739 - lr: 1.0000e-04\n",
            "Epoch 65/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 32.9026 - val_loss: 51.9141 - lr: 1.0000e-04\n",
            "Epoch 66/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 34.7280 - val_loss: 33.9977 - lr: 1.0000e-04\n",
            "Epoch 67/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 32.3086 - val_loss: 31.3799 - lr: 1.0000e-04\n",
            "Epoch 68/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 30.7220 - val_loss: 44.9738 - lr: 1.0000e-04\n",
            "Epoch 69/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 27.3398 - val_loss: 40.7291 - lr: 1.0000e-04\n",
            "Epoch 70/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 29.7877 - val_loss: 26.7132 - lr: 1.0000e-04\n",
            "Epoch 71/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 29.6931 - val_loss: 39.8779 - lr: 1.0000e-04\n",
            "Epoch 72/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 28.5088 - val_loss: 31.4611 - lr: 1.0000e-04\n",
            "Epoch 73/102\n",
            "13/13 [==============================] - ETA: 0s - loss: 27.7981\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "13/13 [==============================] - 39s 3s/step - loss: 27.7981 - val_loss: 29.1324 - lr: 1.0000e-04\n",
            "Epoch 74/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 28.6198 - val_loss: 44.4035 - lr: 1.0000e-05\n",
            "Epoch 75/102\n",
            "13/13 [==============================] - 40s 3s/step - loss: 27.8707 - val_loss: 41.3949 - lr: 1.0000e-05\n",
            "Epoch 76/102\n",
            "13/13 [==============================] - ETA: 0s - loss: 25.0513\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "13/13 [==============================] - 40s 3s/step - loss: 25.0513 - val_loss: 27.4801 - lr: 1.0000e-05\n",
            "Epoch 77/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 27.4735 - val_loss: 27.5268 - lr: 1.0000e-06\n",
            "Epoch 78/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 28.4865 - val_loss: 40.9711 - lr: 1.0000e-06\n",
            "Epoch 79/102\n",
            "13/13 [==============================] - ETA: 0s - loss: 28.9922\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "13/13 [==============================] - 38s 3s/step - loss: 28.9922 - val_loss: 39.0673 - lr: 1.0000e-06\n",
            "Epoch 80/102\n",
            "13/13 [==============================] - 39s 3s/step - loss: 26.2943 - val_loss: 37.6959 - lr: 1.0000e-07\n",
            "Epoch 80: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/TrainYourOwnYOLO/Data/Source_Images/Test_Image_Detection_Results\"\n",
        "for i in os.listdir(path):\n",
        "  if not os.path.isdir(os.path.join(path,i)):\n",
        "    os.remove(os.path.join(path,i))\n"
      ],
      "metadata": {
        "id": "ue5Mm-nJdmek"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "path_to_zip_file = \"/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/test_images.zip\"\n",
        "directory_to_extract_to = \"/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images\"\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "IZJUA4rZuePK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/TrainYourOwnYOLO/3_Inference/Detector.py --postfix \"digit\" --gpu_num 1 --is_tiny "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzI82qmpxFb2",
        "outputId": "19810e4f-8729-4263-fd96-ed043a6dbb6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-12 11:26:56.897701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-12 11:26:59.667413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-12 11:26:59.682816: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-12 11:26:59.682923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7a7dbdb1743e): /proc/driver/nvidia/version does not exist\n",
            "2022-03-12 11:26:59.683763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-12 11:26:59.691803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200180000 Hz\n",
            "2022-03-12 11:26:59.692120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d41132680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-12 11:26:59.692169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "/content/TrainYourOwnYOLO/Data/Model_Weights/trained_weights_final.h5 model, anchors, and classes loaded in 1.67sec.\n",
            "Found 10 input labels: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] ...\n",
            "Found 20 input images: ['zzsvavnora.jpeg', 'zzpkxgxpvb.jpeg', 'zzqqvdnwao.jpeg', 'zzozajtbjk.jpeg', 'zztnlrisiq.jpeg'] ...\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzsvavnora.jpeg\n",
            "(416, 416, 3)\n",
            "2022-03-12 11:27:02.474310: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2022-03-12 11:27:02.557791: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "Found 2 boxes for img\n",
            "0 0.47 (1997, 1406) (2273, 1562)\n",
            "0 0.70 (1859, 2273) (2082, 2525)\n",
            "Time spent: 0.683sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzpkxgxpvb.jpeg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.287sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzqqvdnwao.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "1 0.29 (3028, 1718) (3442, 2907)\n",
            "Time spent: 0.311sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzozajtbjk.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "5 0.29 (0, 1126) (579, 1489)\n",
            "Time spent: 0.307sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zztnlrisiq.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.41 (2588, 1209) (3882, 2047)\n",
            "Time spent: 0.287sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzqilgnnss.jpeg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.286sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzzprpowhq.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.38 (2174, 1895) (2471, 2255)\n",
            "Time spent: 0.309sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzzrkybtcr.jpeg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "0 0.33 (94, 3346) (676, 3872)\n",
            "0 0.81 (673, 166) (2735, 2740)\n",
            "Time spent: 0.301sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzrkgbilhz.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.42 (1018, 2161) (1678, 2829)\n",
            "Time spent: 0.292sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzpgaamisl.jpeg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "0 0.55 (983, 242) (1606, 1014)\n",
            "0 0.60 (404, 3348) (584, 3574)\n",
            "Time spent: 0.303sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzrwrgjxoi.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.72 (3464, 1864) (3706, 2040)\n",
            "Time spent: 0.297sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzqmjanpmx.jpeg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.293sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzpvypubos.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "3 0.28 (2453, 1314) (2579, 1446)\n",
            "Time spent: 0.290sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzuqadxamx.jpeg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "5 0.51 (1445, 1384) (2722, 2732)\n",
            "0 0.32 (1445, 1384) (2722, 2732)\n",
            "0 0.67 (167, 1415) (405, 1598)\n",
            "Time spent: 0.296sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzvjljhlij.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.37 (1515, 289) (3262, 1979)\n",
            "Time spent: 0.291sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzuqwrgxbx.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.55 (2003, 2917) (2413, 3890)\n",
            "Time spent: 0.276sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzvodercgx.jpeg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "0 0.39 (2436, 3207) (2932, 3540)\n",
            "0 0.44 (295, 2560) (680, 2736)\n",
            "Time spent: 0.301sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzrrkaoelj.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.31 (2850, 575) (3489, 1487)\n",
            "Time spent: 0.291sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzrnormnpk.jpeg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "0 0.30 (2108, 3214) (2342, 3519)\n",
            "Time spent: 0.303sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/zzrcxptinq.jpeg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.298sec\n",
            "Processed 20 images in 16.1sec - 1.2FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yV0qV3w832rM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}